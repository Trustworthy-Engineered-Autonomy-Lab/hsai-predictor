

# How Safe Am I Given What I See?

**Calibrated Prediction of Safety Chances for Image-Controlled Autonomy**

This is the code for paper: "How Safe Am I Given What I See?  Calibrated Prediction of Safety Chances for Image-Controlled Autonomy"


## Prerequisites

```python
pip install -r requirements.txt
```

## Train the controllers
