


@article{mnih2013playing,
	title={Playing atari with deep reinforcement learning},
	author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	journal={arXiv preprint arXiv:1312.5602},
	year={2013}
}
@article{DBLP:journals/corr/PintoDSG17,
  author    = {Lerrel Pinto and
               James Davidson and
               Rahul Sukthankar and
               Abhinav Gupta},
  title     = {Robust Adversarial Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1703.02702},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.02702},
  archivePrefix = {arXiv},
  eprint    = {1703.02702},
  timestamp = {Fri, 05 Apr 2019 07:29:46 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/PintoDSG17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{NEURIPS2018_69386f6b,
 author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {6571--6583},
 publisher = {Curran Associates, Inc.},
 title = {Neural Ordinary Differential Equations},
 url = {https://proceedings.neurips.cc/paper/2018/file/69386f6bb1dfed68692a24c8686939b9-Paper.pdf},
 volume = {31},
 year = {2018}
}

@article{DBLP:journals/corr/abs-1903-00374,
  author    = {Lukasz Kaiser and
               Mohammad Babaeizadeh and
               Piotr Milos and
               Blazej Osinski and
               Roy H. Campbell and
               Konrad Czechowski and
               Dumitru Erhan and
               Chelsea Finn and
               Piotr Kozakowski and
               Sergey Levine and
               Ryan Sepassi and
               George Tucker and
               Henryk Michalewski},
  title     = {Model-Based Reinforcement Learning for Atari},
  journal   = {CoRR},
  volume    = {abs/1903.00374},
  year      = {2019},
  url       = {http://arxiv.org/abs/1903.00374},
  archivePrefix = {arXiv},
  eprint    = {1903.00374},
  timestamp = {Sat, 30 Mar 2019 19:27:21 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1903-00374.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{brockman2016openai,
  abstract = {OpenAI Gym is a toolkit for reinforcement learning research. It includes a
growing collection of benchmark problems that expose a common interface, and a
website where people can share their results and compare the performance of
algorithms. This whitepaper discusses the components of OpenAI Gym and the
design decisions that went into the software.},
  added-at = {2018-04-12T12:08:39.000+0200},
  author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  biburl = {https://www.bibsonomy.org/bibtex/2cdc8f927d6c8657ea82951a09e34161a/achakraborty},
  description = {[1606.01540] OpenAI Gym},
  interhash = {cfd0ba0b44eda9a3ca67480dfbf823a0},
  intrahash = {cdc8f927d6c8657ea82951a09e34161a},
  keywords = {2016 arxiv paper reinforcement-learning},
  note = {cite arxiv:1606.01540},
  timestamp = {2018-04-12T12:08:39.000+0200},
  title = {OpenAI Gym},
  url = {http://arxiv.org/abs/1606.01540},
  year = 2016
}



@article{Silver_2016,
  added-at = {2016-03-11T14:36:05.000+0100},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/29e987f58d895c490144693139cbc90c7/ytyoun},
  doi = {10.1038/nature16961},
  interhash = {48430c7891aaf9fe2582faa8f5d076c1},
  intrahash = {9e987f58d895c490144693139cbc90c7},
  journal = {Nature},
  keywords = {baduk go google},
  month = jan,
  number = 7587,
  pages = {484--489},
  publisher = {Nature Publishing Group},
  timestamp = {2016-03-11T14:37:40.000+0100},
  title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
  volume = 529,
  year = 2016
}

@article{DBLP:journals/corr/abs-1912-03513,
  author    = {Warren B. Powell},
  title     = {From Reinforcement Learning to Optimal Control: {A} unified framework
               for sequential decisions},
  journal   = {CoRR},
  volume    = {abs/1912.03513},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.03513},
  archivePrefix = {arXiv},
  eprint    = {1912.03513},
  timestamp = {Thu, 02 Jan 2020 18:08:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1912-03513.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Starcraft,
author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech and Mathieu, MichaÃ«l and Dudzik, Andrew and Chung, Junyoung and Choi, David and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John and Jaderberg, Max and Silver, David},
year = {2019},
month = {11},
pages = {},
title = {Grandmaster level in StarCraft II using multi-agent reinforcement learning},
volume = {575},
journal = {Nature},
doi = {10.1038/s41586-019-1724-z}
}

@book{sutton1998introduction,
	title={Introduction to reinforcement learning},
	author={Sutton, Richard S and Barto, Andrew G and others},
	volume={2},
	number={4},
	year={1998},
	publisher={MIT press Cambridge}
}

@book{goodfellow2016deep,
	title={Deep learning},
	author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year={2016},
	publisher={MIT press}
}

@article{barto1994reinforcement,
	title={Reinforcement learning control},
	author={Barto, Andrew G},
	journal={Current opinion in neurobiology},
	volume={4},
	number={6},
	pages={888--893},
	year={1994},
	publisher={Elsevier}
}

@article{vemulavision,
	title={Vision-based Deep Reinforcement Learning},
	author={Vemula, Anirudh and Dwibedi, Debidatta},
	year={2016}
}

@article{rastogi2017deep,
	title={Deep Reinforcement Learning for Bipedal Robots},
	author={Rastogi, Divyam},
	year={2017}
}

@inproceedings{lample2017playing,
	title={Playing FPS games with deep reinforcement learning},
	author={Lample, Guillaume and Chaplot, Devendra Singh},
	booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
	year={2017}
}

@article{appiahplaying,
	title={Playing FlappyBird with Deep Reinforcement Learning},
	author={Appiah, Naveen and Vare, Sagar}
}

@article{arulkumaran2017deep,
	title={Deep reinforcement learning: A brief survey},
	author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
	journal={IEEE Signal Processing Magazine},
	volume={34},
	number={6},
	pages={26--38},
	year={2017},
	publisher={IEEE}
}

@inproceedings{quillen2018deep,
	title={Deep reinforcement learning for vision-based robotic grasping: A simulated comparative evaluation of off-policy methods},
	author={Quillen, Deirdre and Jang, Eric and Nachum, Ofir and Finn, Chelsea and Ibarz, Julian and Levine, Sergey},
	booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
	pages={6284--6291},
	year={2018},
	organization={IEEE}
}

@phdthesis{nichols2014reinforcement,
	title={Reinforcement learning in continuous state-and action-space},
	author={Nichols, Barry D},
	year={2014},
	school={University of Westminster}
}

@article{zhang2015towards,
	title={Towards vision-based deep reinforcement learning for robotic motion control},
	author={Zhang, Fangyi and Leitner, J{\"u}rgen and Milford, Michael and Upcroft, Ben and Corke, Peter},
	journal={arXiv preprint arXiv:1511.03791},
	year={2015}
}


@article{chen2018comparing,
	title={Comparing Deep Reinforcement Learning Methods for Engineering Applications},
	author={Chen, Shengnan},
	year={2018}
}

@inproceedings{gu2016continuous,
	title={Continuous deep q-learning with model-based acceleration},
	author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
	booktitle={International Conference on Machine Learning},
	pages={2829--2838},
	year={2016}
}

@phdthesis{hochlander2014deep,
	title={Deep Learning for Reinforcement Learning in Pacman},
	author={Hochl{\"a}nder, Aaron},
	year={2014}
}

@inproceedings{schulman2015trust,
	title={Trust region policy optimization},
	author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
	booktitle={International conference on machine learning},
	pages={1889--1897},
	year={2015}
}

@article{lillicrap2015continuous,
	title={Continuous control with deep reinforcement learning},
	author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	journal={arXiv preprint arXiv:1509.02971},
	year={2015}
}

@article{metropolis1949monte,
	title={The monte carlo method},
	author={Metropolis, Nicholas and Ulam, Stanislaw},
	journal={Journal of the American statistical association},
	volume={44},
	number={247},
	pages={335--341},
	year={1949},
	publisher={Taylor \& Francis}
}

@book{bertsekas1995dynamic,
	title={Dynamic programming and optimal control},
	author={Bertsekas, Dimitri P and Bertsekas, Dimitri P and Bertsekas, Dimitri P and Bertsekas, Dimitri P},
	volume={1},
	number={2},
	year={1995},
	publisher={Athena scientific Belmont, MA}
}

@article{watkins1992q,
	title={Q-learning},
	author={Watkins, Christopher JCH and Dayan, Peter},
	journal={Machine learning},
	volume={8},
	number={3-4},
	pages={279--292},
	year={1992},
	publisher={Springer}
}

@inproceedings{nair2010rectified,
	title={Rectified linear units improve restricted boltzmann machines},
	author={Nair, Vinod and Hinton, Geoffrey E},
	booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
	pages={807--814},
	year={2010}
}

@article{schaul2015prioritized,
	title={Prioritized experience replay},
	author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	journal={arXiv preprint arXiv:1511.05952},
	year={2015}
}

@article{schulman2015high,
	title={High-dimensional continuous control using generalized advantage estimation},
	author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
	journal={arXiv preprint arXiv:1506.02438},
	year={2015}
}

@inproceedings{levine2013guided,
	title={Guided policy search},
	author={Levine, Sergey and Koltun, Vladlen},
	booktitle={International Conference on Machine Learning},
	pages={1--9},
	year={2013}
}

@inproceedings{konda2000actor,
	title={Actor-critic algorithms},
	author={Konda, Vijay R and Tsitsiklis, John N},
	booktitle={Advances in neural information processing systems},
	pages={1008--1014},
	year={2000}
}

@article{silver2017mastering,
	title={Mastering the game of go without human knowledge},
	author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
	journal={Nature},
	volume={550},
	number={7676},
	pages={354},
	year={2017},
	publisher={Nature Publishing Group}
}

@article{kingma2014adam,
	title={Adam: A method for stochastic optimization},
	author={Kingma, Diederik P and Ba, Jimmy},
	journal={arXiv preprint arXiv:1412.6980},
	year={2014}
}

@article{srivastava2014dropout,
	title={Dropout: a simple way to prevent neural networks from overfitting},
	author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	journal={The journal of machine learning research},
	volume={15},
	number={1},
	pages={1929--1958},
	year={2014},
	publisher={JMLR. org}
}

@inproceedings{hershey2007approximating,
	title={Approximating the Kullback Leibler divergence between Gaussian mixture models},
	author={Hershey, John R and Olsen, Peder A},
	booktitle={2007 IEEE International Conference on Acoustics, Speech and Signal Processing-ICASSP'07},
	volume={4},
	pages={IV--317},
	year={2007},
	organization={IEEE}
}

@article{DBLP:journals/corr/abs-1907-03098,
	author    = {Elit Cenk Alp and
	Mehmet Serdar G{\"{u}}zel},
	title     = {Playing Flappy Bird via Asynchronous Advantage Actor Critic Algorithm},
	journal   = {CoRR},
	volume    = {abs/1907.03098},
	year      = {2019},
	url       = {http://arxiv.org/abs/1907.03098},
	archivePrefix = {arXiv},
	eprint    = {1907.03098},
	timestamp = {Wed, 17 Jul 2019 10:27:36 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1907-03098},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/BabaeizadehFTCK16,
	author    = {Mohammad Babaeizadeh and
	Iuri Frosio and
	Stephen Tyree and
	Jason Clemons and
	Jan Kautz},
	title     = {{GA3C:} GPU-based {A3C} for Deep Reinforcement Learning},
	journal   = {CoRR},
	volume    = {abs/1611.06256},
	year      = {2016},
	url       = {http://arxiv.org/abs/1611.06256},
	archivePrefix = {arXiv},
	eprint    = {1611.06256},
	timestamp = {Mon, 13 Aug 2018 16:48:01 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/BabaeizadehFTCK16},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/HasseltGS15,
	author    = {Hado van Hasselt and
	Arthur Guez and
	David Silver},
	title     = {Deep Reinforcement Learning with Double Q-learning},
	journal   = {CoRR},
	volume    = {abs/1509.06461},
	year      = {2015},
	url       = {http://arxiv.org/abs/1509.06461},
	archivePrefix = {arXiv},
	eprint    = {1509.06461},
	timestamp = {Mon, 13 Aug 2018 16:47:32 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/HasseltGS15},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/abs-1903-06372,
	author    = {Wesley Suttle and
	Zhuoran Yang and
	Kaiqing Zhang and
	Zhaoran Wang and
	Tamer Basar and
	Ji Liu},
	title     = {A Multi-Agent Off-Policy Actor-Critic Algorithm for Distributed Reinforcement
	Learning},
	journal   = {CoRR},
	volume    = {abs/1903.06372},
	year      = {2019},
	url       = {http://arxiv.org/abs/1903.06372},
	archivePrefix = {arXiv},
	eprint    = {1903.06372},
	timestamp = {Mon, 01 Apr 2019 14:07:37 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1903-06372},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/WangBHMMKF16,
	author    = {Ziyu Wang and
	Victor Bapst and
	Nicolas Heess and
	Volodymyr Mnih and
	R{\'{e}}mi Munos and
	Koray Kavukcuoglu and
	Nando de Freitas},
	title     = {Sample Efficient Actor-Critic with Experience Replay},
	journal   = {CoRR},
	volume    = {abs/1611.01224},
	year      = {2016},
	url       = {http://arxiv.org/abs/1611.01224},
	archivePrefix = {arXiv},
	eprint    = {1611.01224},
	timestamp = {Mon, 13 Aug 2018 16:48:29 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/WangBHMMKF16},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/WangFL15,
	author    = {Ziyu Wang and
	Nando de Freitas and
	Marc Lanctot},
	title     = {Dueling Network Architectures for Deep Reinforcement Learning},
	journal   = {CoRR},
	volume    = {abs/1511.06581},
	year      = {2015},
	url       = {http://arxiv.org/abs/1511.06581},
	archivePrefix = {arXiv},
	eprint    = {1511.06581},
	timestamp = {Mon, 13 Aug 2018 16:48:17 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/WangFL15},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/MahsereciBLH17,
	author    = {Maren Mahsereci and
	Lukas Balles and
	Christoph Lassner and
	Philipp Hennig},
	title     = {Early Stopping without a Validation Set},
	journal   = {CoRR},
	volume    = {abs/1703.09580},
	year      = {2017},
	url       = {http://arxiv.org/abs/1703.09580},
	archivePrefix = {arXiv},
	eprint    = {1703.09580},
	timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/MahsereciBLH17},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/MnihBMGLHSK16,
	author    = {Volodymyr Mnih and
	Adri{\`{a}} Puigdom{\`{e}}nech Badia and
	Mehdi Mirza and
	Alex Graves and
	Timothy P. Lillicrap and
	Tim Harley and
	David Silver and
	Koray Kavukcuoglu},
	title     = {Asynchronous Methods for Deep Reinforcement Learning},
	journal   = {CoRR},
	volume    = {abs/1602.01783},
	year      = {2016},
	url       = {http://arxiv.org/abs/1602.01783},
	archivePrefix = {arXiv},
	eprint    = {1602.01783},
	timestamp = {Mon, 13 Aug 2018 16:47:40 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/MnihBMGLHSK16},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}